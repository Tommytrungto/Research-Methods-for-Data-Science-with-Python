{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TommyTo_MachineTranslation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1EsoNFU-MiRyLZLP0VHfxS5oQqr3QWvmc",
      "authorship_tag": "ABX9TyNBKofK2+wWfAQ6kp3BNoHO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tommytrungto/Research-Methods-for-Data-Science-with-Python/blob/master/TommyTo_MachineTranslation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-v3jFD7hSRp"
      },
      "source": [
        "**Install and Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OGkAZ1zfMV1"
      },
      "source": [
        "!pip install --upgrade tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4ZAPpkjExyO"
      },
      "source": [
        "!pip install nltk\n",
        "\n",
        "!pip install gensim\n",
        "\n",
        "!pip install spacy\n",
        "\n",
        "!pip install plotly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyUfq03rftpA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a169f2f2-f58e-4f18-a368-ff13716dcf1c"
      },
      "source": [
        "import nltk \n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HxMxvxVHBa7"
      },
      "source": [
        "from collections import Counter\n",
        "import operator\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import nltk\n",
        "import re\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, TimeDistributed, RepeatVector, Embedding, Input, LSTM, Conv1D, MaxPool1D, Bidirectional\n",
        "from tensorflow.keras.models import Model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg34fANqHbR7"
      },
      "source": [
        "!pip install jupyterthemes\n",
        "from jupyterthemes import jtplot\n",
        "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvBGdgNIHrZG"
      },
      "source": [
        "#import data from Google Drive\n",
        "df_english = pd.read_csv('/content/drive/My Drive/PhrasesEnglish.csv', sep = '/t', names = ['english'])\n",
        "df_french = pd.read_csv('/content/drive/My Drive/PhrasesFrench.csv', sep = '/t', names = ['french'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWaTYrwoJIRc"
      },
      "source": [
        "df_french.info()\n",
        "df_english.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO7WoBXphH9f"
      },
      "source": [
        "**Data Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpVWWbmDKAUJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "f4bff3e1-7e5c-471e-ae06-d0acaeea4a16"
      },
      "source": [
        "#Concatenation\n",
        "df = pd.concat([df_french, df_english], axis=1)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>french</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>new jersey est parfois calme pendant l' automn...</td>\n",
              "      <td>new jersey is sometimes quiet during autumn , ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>les états-unis est généralement froid en juill...</td>\n",
              "      <td>the united states is usually chilly during jul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>california est généralement calme en mars , et...</td>\n",
              "      <td>california is usually quiet during march , and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>les états-unis est parfois légère en juin , et...</td>\n",
              "      <td>the united states is sometimes mild during jun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>votre moins aimé fruit est le raisin , mais mo...</td>\n",
              "      <td>your least liked fruit is the grape , but my l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137855</th>\n",
              "      <td>la france est jamais occupée en mars , et il e...</td>\n",
              "      <td>france is never busy during march , and it is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137856</th>\n",
              "      <td>l' inde est parfois belle au printemps , et il...</td>\n",
              "      <td>india is sometimes beautiful during spring , a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137857</th>\n",
              "      <td>l' inde est jamais mouillé pendant l' été , ma...</td>\n",
              "      <td>india is never wet during summer , but it is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137858</th>\n",
              "      <td>la france est jamais froid en janvier , mais i...</td>\n",
              "      <td>france is never chilly during january , but it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137859</th>\n",
              "      <td>l'orange est son fruit préféré , mais la banan...</td>\n",
              "      <td>the orange is her favorite fruit , but the ban...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>137860 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   french                                            english\n",
              "0       new jersey est parfois calme pendant l' automn...  new jersey is sometimes quiet during autumn , ...\n",
              "1       les états-unis est généralement froid en juill...  the united states is usually chilly during jul...\n",
              "2       california est généralement calme en mars , et...  california is usually quiet during march , and...\n",
              "3       les états-unis est parfois légère en juin , et...  the united states is sometimes mild during jun...\n",
              "4       votre moins aimé fruit est le raisin , mais mo...  your least liked fruit is the grape , but my l...\n",
              "...                                                   ...                                                ...\n",
              "137855  la france est jamais occupée en mars , et il e...  france is never busy during march , and it is ...\n",
              "137856  l' inde est parfois belle au printemps , et il...  india is sometimes beautiful during spring , a...\n",
              "137857  l' inde est jamais mouillé pendant l' été , ma...  india is never wet during summer , but it is s...\n",
              "137858  la france est jamais froid en janvier , mais i...  france is never chilly during january , but it...\n",
              "137859  l'orange est son fruit préféré , mais la banan...  the orange is her favorite fruit , but the ban...\n",
              "\n",
              "[137860 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVzu2obVKXRx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5896a708-7309-4b33-850a-f49c90191d7b"
      },
      "source": [
        "print('Total French phrases: {}'. format(len(df_french)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total French phrases: 137860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H_vNLOIMhf8"
      },
      "source": [
        "#this function returns phrases without punctuations\n",
        "def remove_punctuations(x):\n",
        "  return re.sub('[!#?,.:\";]','',x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQxDDRQNM7Qq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4167a01-930e-434b-9e45-8a5e16002309"
      },
      "source": [
        "df['english'] = df['english'].apply(remove_punctuations)\n",
        "df['french'] = df['french'].apply(remove_punctuations)\n",
        "df['english']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         new jersey is sometimes quiet during autumn  a...\n",
              "1         the united states is usually chilly during jul...\n",
              "2         california is usually quiet during march  and ...\n",
              "3         the united states is sometimes mild during jun...\n",
              "4         your least liked fruit is the grape  but my le...\n",
              "                                ...                        \n",
              "137855    france is never busy during march  and it is s...\n",
              "137856    india is sometimes beautiful during spring  an...\n",
              "137857    india is never wet during summer  but it is so...\n",
              "137858    france is never chilly during january  but it ...\n",
              "137859    the orange is her favorite fruit  but the bana...\n",
              "Name: english, Length: 137860, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwW9SAKNdVY0"
      },
      "source": [
        "#list of unique english and french words:\n",
        "unique_english_words = []\n",
        "unique_french_words = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_3ArWS1ckRK"
      },
      "source": [
        "#this function returns unique word list:\n",
        "def get_unique_words(x, word_list):\n",
        "  for word in x.split():\n",
        "    if word not in word_list:\n",
        "      word_list.append(word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd61s7j6d55V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ffb0874-d8e2-4980-bcdd-af1ad0176935"
      },
      "source": [
        "df['english'].apply(lambda x: get_unique_words(x,unique_english_words))\n",
        "len(unique_english_words)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEPSgoJufdnu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f75f49e-0e33-44a3-a4c5-c6020ebc1681"
      },
      "source": [
        "df['french'].apply(lambda x:get_unique_words(x,unique_french_words))\n",
        "len(unique_french_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "350"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBixrat0h0uV"
      },
      "source": [
        "total_english_words = []\n",
        "for phrase in df['english']:\n",
        "  for word in phrase.split():\n",
        "    total_english_words.append(word)\n",
        "english_words_counts = Counter(total_english_words)\n",
        "#Words are sorted by alphabetical order by default\n",
        "english_words_counts\n",
        "#sort the words by values\n",
        "english_words_counts = sorted(english_words_counts.items(), key = operator.itemgetter(1), reverse = True)\n",
        "english_words_counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UwwJX6likYo"
      },
      "source": [
        "#use Counter and sorted to return words and their counts from high to low\n",
        "total_french_words = []\n",
        "for phrase in df['french']:\n",
        "  for word in phrase.split():\n",
        "    total_french_words.append(word)\n",
        "french_words_counts = Counter(total_french_words)\n",
        "len(french_words_counts)\n",
        "french_words_counts = sorted(french_words_counts.items(), key = operator.itemgetter(1), reverse = True)\n",
        "#List of all the words and their counts\n",
        "french_words_counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtNoXaJ_hMvT"
      },
      "source": [
        "**Data Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1NJsGp2t5Me"
      },
      "source": [
        "#split words [0] and counts [1] for visualization purpose\n",
        "english_words = []\n",
        "english_counts = []\n",
        "\n",
        "for i in range(len(english_words_counts)):\n",
        "  english_words.append(english_words_counts[i][0])\n",
        "  english_counts.append(english_words_counts[i][1])\n",
        "\n",
        "english_counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "883JHeZsxDcQ"
      },
      "source": [
        "#french words and counts\n",
        "french_words = []\n",
        "french_counts = []\n",
        "\n",
        "for i in range(len(french_words_counts)):\n",
        "  french_words.append(french_words_counts[i][0])\n",
        "  french_counts.append(french_words_counts[i][1])\n",
        "\n",
        "french_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjQd_nVt3dbG"
      },
      "source": [
        "plt.figure(figsize = (20,20))\n",
        "wc = WordCloud(max_words = 200, width = 1600, height = 800).generate(\"\".join(df.french))\n",
        "plt.imshow(wc, interpolation='bessel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY3Fu63HhOxb"
      },
      "source": [
        "#Interactive barplot of english words and their frequency\n",
        "#pl: plotly.express library\n",
        "fig = px.bar(x = english_words, y = english_counts)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHLMzLv6x1vU"
      },
      "source": [
        "#wordCloud\n",
        "plt.figure(figsize=(20,20))\n",
        "wc = WordCloud(max_words = 200, width = 1600, height = 800).generate(\" \".join(df.english))\n",
        "plt.imshow(wc, interpolation = 'bilinear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6bQ2lj_7pnb"
      },
      "source": [
        "df.english[0]\n",
        "nltk.word_tokenize(df.english[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11idxz_ezQjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f487ef3-fbbf-402d-c88b-d96929f64341"
      },
      "source": [
        "#tokenize english phrases\n",
        "maxlen_english = 0\n",
        "for phrase in df.english:\n",
        "  tokens = nltk.word_tokenize(phrase)\n",
        "  if(maxlen_english < len(tokens)):\n",
        "    maxlen_english = len(tokens)\n",
        "print(\"The maximum number of words in any phrase = \", maxlen_english)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The maximum number of words in any phrase =  15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r66KOK0_5AUr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d00db1aa-4a3a-449f-c658-d3a7e6b84cb3"
      },
      "source": [
        "#tokenize french phrases\n",
        "maxlen_french = -1\n",
        "for phrase in df.french:\n",
        "  tokens = nltk.word_tokenize(phrase)\n",
        "  if(maxlen_french < len(tokens)):\n",
        "    maxlen_french = len(tokens)\n",
        "maxlen_french"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULPfWKGLCRcX"
      },
      "source": [
        "**Tokenization and Padding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j6OVCjtCPek"
      },
      "source": [
        "def tokenize_and_pad(df, maxlen):\n",
        "  tokenizer = Tokenizer(char_level=False)\n",
        "  #fit_on_texts returns word-index based on frequency\n",
        "  tokenizer.fit_on_texts(df)\n",
        "  #texts_to_sequence returns sequence of integers from word-index\n",
        "  sequences = tokenizer.texts_to_sequences(df)\n",
        "  #pad_sequences added 0 so that all the sequences have the same length\n",
        "  padded = pad_sequences(sequences, maxlen=maxlen, padding = 'post')\n",
        "  return tokenizer, sequences, padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6kDxilYE2Zi"
      },
      "source": [
        "eng_tokenizer, eng_sequences, eng_padded = tokenize_and_pad(df.english, maxlen_english)\n",
        "fr_tokenizer, fr_sequences, fr_padded = tokenize_and_pad(df.french, maxlen_french)\n",
        "\n",
        "fr_padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwoh9zsYGW1O"
      },
      "source": [
        "print(\"The tokenized version for the last phrase of french df is:\\n\", df.french[-1:].item(),\" \\n\", fr_padded[-1:])\n",
        "print(\"\\n\")\n",
        "print(\"The tokenized version for the last phrase of english df is:\\n\", df.english[-1:].item(),\" \\n\", eng_padded[-1:])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II_acvqeHYdI"
      },
      "source": [
        "#Split train amd test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "eng_train, eng_test, fr_train, fr_test = train_test_split(eng_padded, fr_padded, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJEuYsiLLZsq"
      },
      "source": [
        "Gradient Descent: an optimization technique, iteratively minimize the cost function. Long term short term memory(LSTM) to overcome Vanishing Gradient problem.\n",
        "LSTM uses a horizontal line memory(cell state) to remember and recell information for a prolonged period of time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szCAHGbmP4Vx"
      },
      "source": [
        "Encoder-Decoder Model\n",
        "French -> Embedding Layer -> LSTM (Encoder) -> (RepeatVector -> LSTM) Decoder -> TimeDistributed(Dense) ->English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dONTzNFtP4DI"
      },
      "source": [
        "eng_vocab_size = len(unique_english_words) + 1 \n",
        "\n",
        "fr_vocab_size = len(unique_french_words) + 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkWAV0FxQv5j"
      },
      "source": [
        "#Sequential Model\n",
        "model = Sequential()\n",
        "#Embedding Layer \n",
        "model.add(Embedding(fr_vocab_size, 256, input_length = maxlen_french, mask_zero = True))\n",
        "#Encoder\n",
        "model.add(LSTM(256))\n",
        "#Decoder\n",
        "model.add(RepeatVector(maxlen_english))\n",
        "model.add(LSTM(256, return_sequences = True))\n",
        "#Dense layer\n",
        "model.add(TimeDistributed(Dense(eng_vocab_size, activation = 'softmax')))\n",
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAUMViijWaXy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbe28188-e339-4231-983f-9b290a652a62"
      },
      "source": [
        "#Change french shape from 2D to 3D\n",
        "eng_train = np.expand_dims(eng_train, axis = 2)\n",
        "eng_train = eng_train.reshape(eng_train.shape[:3])\n",
        "eng_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(117181, 15, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLmCwskxc4CY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab4323a3-2e53-46d0-eb76-5b099d8332f1"
      },
      "source": [
        "len(eng_train)\n",
        "#512-0.6312\n",
        "#256-0.6598\n",
        "#128-0.6493"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117181"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TCu1FZfXoPk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3837c90-6e3e-4279-ff08-3916c17bd171"
      },
      "source": [
        "#Train the model\n",
        "model.fit(fr_train, eng_train, batch_size = 1024, validation_split = 0.1, epochs = 17)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "132/132 [==============================] - 314s 2s/step - loss: 0.0513 - accuracy: 0.9781 - val_loss: 0.0513 - val_accuracy: 0.9769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe633431b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LcU87Q_dhJr"
      },
      "source": [
        "**Assess trained model performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7kzF0bKeFxg"
      },
      "source": [
        "#generate french predicted arrays of integers\n",
        "eng_predict = model.predict(fr_test)\n",
        "\n",
        "eng_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnDcNI4YeQIV"
      },
      "source": [
        "def generatePrediction(phrase, eng_tokenizer = eng_tokenizer, fr_tokenizer = fr_tokenizer):\n",
        "  predictions = model.predict(phrase)[0]\n",
        "  id_to_word = {id: word for word, id in eng_tokenizer.word_index.items()}\n",
        "  id_to_word[0] = ''\n",
        "  return ' '.join([id_to_word[j] for j in np.argmax(predictions,1)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPURlQashQLM"
      },
      "source": [
        "def pad_to_text(padded, tokenizer):\n",
        "  id_to_word = {id: word for word, id in tokenizer.word_index.items()}\n",
        "  id_to_word[0] = ''\n",
        "  return ' '.join([id_to_word[j] for j in padded])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzvynaNBhkJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bce3e5a-b8e0-4086-90c1-26f6789c0a3e"
      },
      "source": [
        "for i in range (9):\n",
        "  print('Original French sentence: {}\\n'.format(pad_to_text(fr_test[i], fr_tokenizer)))\n",
        "  print('Original English sentence: {}\\n'.format(pad_to_text(eng_test[i], eng_tokenizer)))\n",
        "  print('Predicted English sentence: {}\\n\\n\\n\\n'.format(generatePrediction(eng_test[i:i+1])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original French sentence: elle déteste les mangues les citrons verts et les pommes             \n",
            "\n",
            "Original English sentence: she dislikes mangoes limes and apples         \n",
            "\n",
            "Predicted English sentence: i is sometimes beautiful march and         \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Original French sentence: paris est jamais merveilleux en juin mais il est relaxant à l' automne          \n",
            "\n",
            "Original English sentence: paris is never wonderful during june but it is relaxing in autumn   \n",
            "\n",
            "Predicted English sentence: india is relaxing during may and it is rainy in summer    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Original French sentence: l' inde est parfois occupée en octobre et il est calme à l' automne         \n",
            "\n",
            "Original English sentence: india is sometimes busy during october and it is quiet in fall   \n",
            "\n",
            "Predicted English sentence: france is sometimes quiet during october but it is quiet in summer   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Original French sentence: la chine est relaxant parfois pendant l' hiver mais il est sec en août         \n",
            "\n",
            "Original English sentence: china is sometimes relaxing during winter but it is dry in august   \n",
            "\n",
            "Predicted English sentence: france is sometimes rainy during january and it is dry in fall   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Original French sentence: la chaux est son fruit moins aimé mais la mangue est mon moins aimé         \n",
            "\n",
            "Original English sentence: the lime is her least liked fruit but the mango is my least liked \n",
            "\n",
            "Predicted English sentence: the strawberry is is sometimes during winter but it is is usually snowy in march\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Original French sentence: la france est généralement humide en juin mais il est généralement merveilleux en mai         \n",
            "\n",
            "Original English sentence: france is usually wet during june but it is usually wonderful in may  \n",
            "\n",
            "Predicted English sentence: india is never busy during autumn and it is never freezing in in  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Original French sentence: new jersey est relaxant en juillet et il est agréable en avril           \n",
            "\n",
            "Original English sentence: new jersey is relaxing during july and it is pleasant in april   \n",
            "\n",
            "Predicted English sentence: the united is is wet during january but it is snowy in winter  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Original French sentence: paris est jamais doux au mois d' août mais il est chaud en juin         \n",
            "\n",
            "Original English sentence: paris is never mild during august but it is hot in june   \n",
            "\n",
            "Predicted English sentence: france is usually relaxing during fall and it is beautiful in fall   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Original French sentence: paris est le gel en mars mais il est parfois doux en mai          \n",
            "\n",
            "Original English sentence: paris is freezing during march but it is sometimes mild in may   \n",
            "\n",
            "Predicted English sentence: france is never busy during november and it is sometimes warm in may  \n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}